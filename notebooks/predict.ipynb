{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common import Params\n",
    "from allennlp.data import DatasetReader\n",
    "from allennlp.data.dataset import Batch\n",
    "from allennlp.data.iterators import BasicIterator, BucketIterator, DataIterator\n",
    "\n",
    "from allennlp.models import Model\n",
    "\n",
    "from allennlp.nn.util import move_to_device\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/emelyanov-yi/PycharmProjects/kaggle_tf2_qa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import NaturalQuestionsModel, NaturalQuestionsDatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Optional\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/home/emelyanov-yi/models/tf2_qa/main_lstm_bert_negatives_0.02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params.from_file(prefix + '/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load(params, prefix).to('cuda')\n",
    "model_device = next(model.parameters()).device\n",
    "vocab = model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = DatasetReader.from_params(params['dataset_reader'].duplicate())\n",
    "reader._downsample_negative = 1.1\n",
    "reader._downsample_all = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_gen = reader.read(params['validation_data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = DataIterator.from_params(params['iterator'].duplicate())\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iterator = iterator(instances_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we store our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list: List[Dict] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.02s/it]Too many wordpieces, truncating sequence. If you would like a sliding window, set `truncate_long_sequences` to False.The offending input was: ['[CLS]', 'the', 'name', 'of', 'the', 'separatist', 'political', 'party', 'in', 'quebec', '[SEP]', '<Ul>', '<Li>', 'Richard', 'Rohmer', \"'s\", 'novel', 'Separation', '(', '1976', ')', 'was', 'turned', 'into', 'a', 'TV', '-', 'movie', 'for', 'CTV', 'Television', 'in', '1977', '.', 'In', 'the', 'movie', ',', 'the', 'Parti', 'Québécois', 'has', 'formed', 'the', 'government', 'of', 'Quebec', 'but', 'Premier', 'Gaston', 'Belisle', 'has', 'repeatedly', 'put', 'off', 'its', 'promise', 'to', 'hold', 'a', 'referendum', '.', 'International', 'politics', 'forces', 'Belisle', \"'s\", 'hand', '.', '</Li>', '<Li>', 'In', 'the', 'mid-1980s', ',', 'a', 'second', 'movie', ',', 'Quebec', '-', 'Canada', '1995', ',', 'depicts', 'a', 'meeting', 'between', 'the', 'president', 'of', 'Quebec', 'and', 'the', 'prime', 'minister', 'of', 'Canada', 'to', 'discuss', 'a', 'crisis', 'involving', 'Quebec', 'military', 'occupations', 'of', 'parts', 'of', 'Ontario', 'and', 'New', 'Brunswick', '.', 'Canada', \"'s\", 'armed', 'forces', 'are', 'stretched', 'thin', 'with', 'peacekeepers', 'in', 'such', 'varied', 'places', 'as', 'the', 'Falkland', 'Islands', '(', 'with', '``', 'Lady', 'Goosegreen', \"''\", 'being', 'Margaret', 'Thatcher', ')', '.', '</Li>', '<Li>', 'William', 'Weintraub', \"'s\", 'satirical', '1979', 'novel', 'The', 'Underdogs', 'provoked', 'controversy', 'by', 'imagining', 'a', 'future', 'Quebec', 'in', 'which', 'English', '-', 'speakers', 'were', 'an', 'oppressed', 'minority', ',', 'complete', 'with', 'a', 'violent', 'resistance', 'movement', '.', 'One', 'planned', 'stage', 'version', 'was', 'cancelled', 'before', 'its', 'premiere', '.', '</Li>', '<Li>', 'Clive', 'Cussler', \"'s\", '1984', 'novel', 'Night', 'Probe', '!', 'is', 'set', 'against', 'a', 'fictional', 'attempt', 'at', 'secession', 'in', 'the', 'late', '1980s', '.', 'Rights', 'to', 'newly', 'discovered', 'oil', 'resources', 'in', 'Ungava', 'Bay', ',', 'discovered', 'as', 'Quebec', 'moves', 'to', 'secede', ',', 'clash', 'with', 'the', 'ramifications', 'of', 'a', 'rediscovered', 'secret', 'treaty', 'negotiated', 'between', 'the', 'U.K.', 'and', 'U.S.', 'governments', 'during', 'World', 'War', 'I', '.', '</Li>', '<Li>', 'David', 'Foster', 'Wallace', \"'s\", 'novel', 'Infinite', 'Jest', 'includes', 'both', 'real', 'and', 'fictional', 'Québécois', 'separatist', 'movements', 'as', 'integral', 'to', 'the', 'plot', '.', 'In', 'the', 'story', ',', 'the', 'United', 'States', 'has', 'merged', 'with', 'Canada', 'and', 'Mexico', 'to', 'form', 'the', 'Organization', 'of', 'North', 'American', 'Nations', '(', 'ONAN', ')', '.', 'Wheelchair', '-', 'bound', 'Quebec', 'separatists', 'use', 'a', 'video', 'so', 'entertaining', 'it', 'leads', 'to', 'death', 'to', 'accomplish', 'their', 'goals', 'of', 'both', 'Quebec', 'independence', 'and', 'the', 'end', 'of', 'the', 'ONAN', '.', '</Li>', '<Li>', 'In', 'the', 'Southern', 'Victory', 'Series', 'of', 'alternate', 'history', 'novels', 'by', 'Harry', 'Turtledove', ',', 'Quebec', 'becomes', 'a', 'separate', 'nation', 'during', 'the', 'First', 'Great', 'War', '(', 'an', 'alternative', 'World', 'War', 'I', ')', ',', 'in', 'which', 'the', 'United', 'States', 'defeats', 'Canada', ',', 'the', 'United', 'Kingdom', 'and', 'the', 'other', 'Entente', 'Powers', '(', 'including', 'the', 'Confederate', 'States', 'of', 'America', ')', ';', 'upon', 'its', 'founding', ',', 'the', 'Republic', 'is', 'officially', 'recognised', 'only', 'by', 'the', 'United', 'States', ',', 'Germany', ',', 'Austria', '-', 'Hungary', ',', 'Bulgaria', ',', 'the', 'Ottoman', 'Empire', ',', 'Poland', ',', 'Ukraine', ',', 'Italy', 'and', 'the', 'Netherlands', '.', 'Since', 'the', 'United', 'States', 'organized', 'this', 'separation', 'to', 'weaken', 'Anglophone', 'Canada', '(', 'and', 'the', 'UK', 'by', 'extension', ')', 'and', 'to', 'aid', 'in', 'the', 'post-war', 'occupation', 'of', 'Canada', ',', 'the', 'Republic', 'of', 'Quebec', 'operated', 'as', 'a', 'client', 'state', 'of', 'the', 'United', 'States', ',', 'rather'].To avoid polluting your logs we will not warn about this again.\n",
      "6023it [2:39:22,  1.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-44ce1eff6316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel_device\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbatch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# returned loss if scalar (0-dimensional tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/kaggle_tf2_qa/src/nq_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context, answer_label, answer_start, answer_end, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Answer start ans answer ends must be provided simultaneously'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_field_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B , L]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B , N , E]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text_field_input, num_wrapping_dims, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     tensors = [(text_field_input[indexer_key] if indexer_key is not None else None)\n\u001b[1;32m    117\u001b[0m                                for indexer_key in indexer_map]\n\u001b[0;32m--> 118\u001b[0;31m                     \u001b[0mtoken_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     tensors = {\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/modules/token_embedders/bert_token_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, offsets, token_type_ids)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# now offsets is (batch_size * d1 * ... * dn, orig_sequence_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             range_vector = util.get_range_vector(offsets2d.size(0),\n\u001b[0;32m--> 239\u001b[0;31m                                                  device=util.get_device_of(mix)).unsqueeze(1)\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;31m# selected embeddings is also (batch_size * d1 * ... * dn, orig_sequence_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mselected_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets2d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36mget_range_vector\u001b[0;34m(size, device)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \"\"\"\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in tqdm(batch_iterator):\n",
    "    batch = move_to_device(batch, 0 if model_device else -1)\n",
    "    batch_results = model(**batch)\n",
    "    for k, v in batch_results.items():\n",
    "        # returned loss if scalar (0-dimensional tensor)\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            batch_results[k] = v.detach().cpu()\n",
    "    batch_size = len(batch_results['meta'])\n",
    "    for i in range(batch_size):\n",
    "        temp_dict = {}\n",
    "        for k, v in batch_results.items():\n",
    "            # returned loss if scalar (0-dimensional tensor)\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                if v.ndim > 0:\n",
    "                    temp_dict[k] = v[i, ...]\n",
    "            elif isinstance(v, list):\n",
    "                temp_dict[k] = v[i]\n",
    "            else:\n",
    "                raise RuntimeError(f'Model returned container of type {type(v)}')\n",
    "        temp_dict.update(**temp_dict['meta'])\n",
    "        results_list.append(temp_dict)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289104"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t context: TextField of length 62 with text: \n",
      " \t\t[[CLS], the, name, of, the, separatist, political, party, in, quebec, [SEP], <Table>, <Tr>, <Td>,\n",
      "\t\t</Td>, <Td>, This, article, needs, additional, citations, for, verification, ., Please, help,\n",
      "\t\timprove, this, article, by, adding, citations, to, reliable, sources, ., Unsourced, material, may,\n",
      "\t\tbe, challenged, and, removed, ., (, April, 2010, ), (, Learn, how, and, when, to, remove, this,\n",
      "\t\ttemplate, message, ), </Td>, </Tr>, </Table>]\n",
      " \t\tand TokenIndexers : {'tokens': 'PretrainedBertIndexer'} \n",
      " \t meta: MetadataField (print field.metadata to see specific information). \n",
      " \t answer_start: IndexField with index: 10. \n",
      " \t answer_end: IndexField with index: 10. \n",
      " \t answer_label: LabelField with label: not_relevant in namespace: 'answer_labels'.' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From predictions for all paragraphs to one document-level prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [00:16, 13.40it/s]Too many wordpieces, truncating sequence. If you would like a sliding window, set `truncate_long_sequences` to False.The offending input was: ['[CLS]', 'the', 'name', 'of', 'the', 'separatist', 'political', 'party', 'in', 'quebec', '[SEP]', '<Ul>', '<Li>', 'Richard', 'Rohmer', \"'s\", 'novel', 'Separation', '(', '1976', ')', 'was', 'turned', 'into', 'a', 'TV', '-', 'movie', 'for', 'CTV', 'Television', 'in', '1977', '.', 'In', 'the', 'movie', ',', 'the', 'Parti', 'Québécois', 'has', 'formed', 'the', 'government', 'of', 'Quebec', 'but', 'Premier', 'Gaston', 'Belisle', 'has', 'repeatedly', 'put', 'off', 'its', 'promise', 'to', 'hold', 'a', 'referendum', '.', 'International', 'politics', 'forces', 'Belisle', \"'s\", 'hand', '.', '</Li>', '<Li>', 'In', 'the', 'mid-1980s', ',', 'a', 'second', 'movie', ',', 'Quebec', '-', 'Canada', '1995', ',', 'depicts', 'a', 'meeting', 'between', 'the', 'president', 'of', 'Quebec', 'and', 'the', 'prime', 'minister', 'of', 'Canada', 'to', 'discuss', 'a', 'crisis', 'involving', 'Quebec', 'military', 'occupations', 'of', 'parts', 'of', 'Ontario', 'and', 'New', 'Brunswick', '.', 'Canada', \"'s\", 'armed', 'forces', 'are', 'stretched', 'thin', 'with', 'peacekeepers', 'in', 'such', 'varied', 'places', 'as', 'the', 'Falkland', 'Islands', '(', 'with', '``', 'Lady', 'Goosegreen', \"''\", 'being', 'Margaret', 'Thatcher', ')', '.', '</Li>', '<Li>', 'William', 'Weintraub', \"'s\", 'satirical', '1979', 'novel', 'The', 'Underdogs', 'provoked', 'controversy', 'by', 'imagining', 'a', 'future', 'Quebec', 'in', 'which', 'English', '-', 'speakers', 'were', 'an', 'oppressed', 'minority', ',', 'complete', 'with', 'a', 'violent', 'resistance', 'movement', '.', 'One', 'planned', 'stage', 'version', 'was', 'cancelled', 'before', 'its', 'premiere', '.', '</Li>', '<Li>', 'Clive', 'Cussler', \"'s\", '1984', 'novel', 'Night', 'Probe', '!', 'is', 'set', 'against', 'a', 'fictional', 'attempt', 'at', 'secession', 'in', 'the', 'late', '1980s', '.', 'Rights', 'to', 'newly', 'discovered', 'oil', 'resources', 'in', 'Ungava', 'Bay', ',', 'discovered', 'as', 'Quebec', 'moves', 'to', 'secede', ',', 'clash', 'with', 'the', 'ramifications', 'of', 'a', 'rediscovered', 'secret', 'treaty', 'negotiated', 'between', 'the', 'U.K.', 'and', 'U.S.', 'governments', 'during', 'World', 'War', 'I', '.', '</Li>', '<Li>', 'David', 'Foster', 'Wallace', \"'s\", 'novel', 'Infinite', 'Jest', 'includes', 'both', 'real', 'and', 'fictional', 'Québécois', 'separatist', 'movements', 'as', 'integral', 'to', 'the', 'plot', '.', 'In', 'the', 'story', ',', 'the', 'United', 'States', 'has', 'merged', 'with', 'Canada', 'and', 'Mexico', 'to', 'form', 'the', 'Organization', 'of', 'North', 'American', 'Nations', '(', 'ONAN', ')', '.', 'Wheelchair', '-', 'bound', 'Quebec', 'separatists', 'use', 'a', 'video', 'so', 'entertaining', 'it', 'leads', 'to', 'death', 'to', 'accomplish', 'their', 'goals', 'of', 'both', 'Quebec', 'independence', 'and', 'the', 'end', 'of', 'the', 'ONAN', '.', '</Li>', '<Li>', 'In', 'the', 'Southern', 'Victory', 'Series', 'of', 'alternate', 'history', 'novels', 'by', 'Harry', 'Turtledove', ',', 'Quebec', 'becomes', 'a', 'separate', 'nation', 'during', 'the', 'First', 'Great', 'War', '(', 'an', 'alternative', 'World', 'War', 'I', ')', ',', 'in', 'which', 'the', 'United', 'States', 'defeats', 'Canada', ',', 'the', 'United', 'Kingdom', 'and', 'the', 'other', 'Entente', 'Powers', '(', 'including', 'the', 'Confederate', 'States', 'of', 'America', ')', ';', 'upon', 'its', 'founding', ',', 'the', 'Republic', 'is', 'officially', 'recognised', 'only', 'by', 'the', 'United', 'States', ',', 'Germany', ',', 'Austria', '-', 'Hungary', ',', 'Bulgaria', ',', 'the', 'Ottoman', 'Empire', ',', 'Poland', ',', 'Ukraine', ',', 'Italy', 'and', 'the', 'Netherlands', '.', 'Since', 'the', 'United', 'States', 'organized', 'this', 'separation', 'to', 'weaken', 'Anglophone', 'Canada', '(', 'and', 'the', 'UK', 'by', 'extension', ')', 'and', 'to', 'aid', 'in', 'the', 'post-war', 'occupation', 'of', 'Canada', ',', 'the', 'Republic', 'of', 'Quebec', 'operated', 'as', 'a', 'client', 'state', 'of', 'the', 'United', 'States', ',', 'rather'].To avoid polluting your logs we will not warn about this again.\n",
      "20358it [40:10,  8.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3ba0a4f0ace3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_on_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mforward_on_instance\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensors\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minto\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_on_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     def forward_on_instances(self,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mforward_on_instances\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0minstance_separated_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/kaggle_tf2_qa/src/nq_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context, answer_label, answer_start, answer_end, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Answer start ans answer ends must be provided simultaneously'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_field_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B , L]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B , N , E]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text_field_input, num_wrapping_dims, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     tensors = [(text_field_input[indexer_key] if indexer_key is not None else None)\n\u001b[1;32m    117\u001b[0m                                for indexer_key in indexer_map]\n\u001b[0;32m--> 118\u001b[0;31m                     \u001b[0mtoken_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     tensors = {\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/modules/token_embedders/bert_token_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, offsets, token_type_ids)\u001b[0m\n\u001b[1;32m    173\u001b[0m         all_encoder_layers, _ = self.bert_model(input_ids=util.combine_initial_dims(input_ids),\n\u001b[1;32m    174\u001b[0m                                                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_initial_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                                                 attention_mask=util.combine_initial_dims(input_mask))\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mInitializes\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m \u001b[0mby\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"python.nn_module\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results: List[Dict] = []\n",
    "for inst in tqdm(instances_gen):\n",
    "    batch = Batch([inst])\n",
    "    batch.index_instances(model.vocab)\n",
    "    res = model.forward_on_instance(inst)\n",
    "    \n",
    "    res.update(**res['meta'])\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docwise_results = defaultdict(list)\n",
    "for res in results_list:\n",
    "    docwise_results[res['example_id']].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['start_logits', 'end_logits', 'label_logits', 'mask', 'meta', 'example_id', 'candidate_start_token', 'text', 'query', 'offset'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2226/2226 [00:00<00:00, 2695.32it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions: Dict[str, Tuple] = {}\n",
    "    \n",
    "for doc_id, all_results in tqdm(docwise_results.items()):\n",
    "    long_answer_candidate = None\n",
    "    for result in all_results:\n",
    "        predicted_label = vocab.get_token_from_index(result['label_logits'].argmax().item(), namespace='answer_labels')\n",
    "        if predicted_label in ['YES', 'NO']:\n",
    "            # when we predict yes-no answer, we use current paragraph as long answer and do not check other paragraphs at all\n",
    "            # TODO: get best match based on logits\n",
    "            predictions[doc_id] = ((result['candidate_start_token'], result['candidate_start_token'] + len(result['text'])), predicted_label)\n",
    "            break\n",
    "        elif predicted_label == 'NONE':\n",
    "            # paragraph is at least relevant, save it if there will be no other such prediction in the future\n",
    "            # get predicted short answer (if exists)\n",
    "            offset = result['offset']\n",
    "            short_answer_start = res['start_logits'].argmax() - offset\n",
    "            short_answer_end = res['end_logits'].argmax() - offset\n",
    "            if short_answer_end >= short_answer_start \\\n",
    "                and short_answer_start >= 0:\n",
    "                # found good short answer, break\n",
    "                predictions[doc_id] = (long_answer_candidate, (short_answer_start, short_answer_end))\n",
    "                break\n",
    "            else:\n",
    "                long_answer_candidate = (result['candidate_start_token'], result['candidate_start_token'] + len(result['text']))\n",
    "    if long_answer_candidate is not None:\n",
    "        predictions[doc_id] = (long_answer_candidate, '')\n",
    "    else:\n",
    "        predictions[doc_id] = ('', '')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission: Dict[str, str] = OrderedDict()\n",
    "for doc_id in docwise_results:\n",
    "    long_answer, short_answer = predictions[doc_id]\n",
    "    if not long_answer:\n",
    "        submission[f'{doc_id}_long'] = ''\n",
    "    else:\n",
    "        submission[f'{doc_id}_long'] = '{}:{}'.format(*long_answer)\n",
    "    if not short_answer:\n",
    "        submission[f'{doc_id}_short'] = ''\n",
    "    elif isinstance(short_answer, str):\n",
    "        submission[f'{doc_id}_short'] = short_answer \n",
    "    elif isinstance(short_answer, tuple):\n",
    "        submission[f'{doc_id}_short'] = '{}:{}'.format(*short_answer)\n",
    "    else:\n",
    "        raise RuntimeError(f'Short answer {short_answer} not understood.')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('-1258974036110822789_long', '79:118'),\n",
       "             ('-1258974036110822789_short', ''),\n",
       "             ('-745542277813407309_long', '90:141'),\n",
       "             ('-745542277813407309_short', ''),\n",
       "             ('-3489053283041023861_long', ''),\n",
       "             ('-3489053283041023861_short', ''),\n",
       "             ('-4660970382607895773_long', ''),\n",
       "             ('-4660970382607895773_short', ''),\n",
       "             ('-2286041252427312305_long', '346:524'),\n",
       "             ('-2286041252427312305_short', ''),\n",
       "             ('-3594846094801386035_long', '805:927'),\n",
       "             ('-3594846094801386035_short', ''),\n",
       "             ('1100531970231406189_long', ''),\n",
       "             ('1100531970231406189_short', ''),\n",
       "             ('-4242445176318660699_long', '130:253'),\n",
       "             ('-4242445176318660699_short', ''),\n",
       "             ('-8610711774716247943_long', ''),\n",
       "             ('-8610711774716247943_short', ''),\n",
       "             ('-7912859676267745845_long', '201:250'),\n",
       "             ('-7912859676267745845_short', ''),\n",
       "             ('1347288971259022029_long', ''),\n",
       "             ('1347288971259022029_short', ''),\n",
       "             ('-1239741599579606102_long', ''),\n",
       "             ('-1239741599579606102_short', ''),\n",
       "             ('-8566118151109196101_long', '160:475'),\n",
       "             ('-8566118151109196101_short', ''),\n",
       "             ('7920718418002827464_long', ''),\n",
       "             ('7920718418002827464_short', ''),\n",
       "             ('4055855179318578860_long', ''),\n",
       "             ('4055855179318578860_short', ''),\n",
       "             ('232664088259764773_long', ''),\n",
       "             ('232664088259764773_short', ''),\n",
       "             ('-5062984347125434513_long', ''),\n",
       "             ('-5062984347125434513_short', ''),\n",
       "             ('-26744207835626469_long', '347:420'),\n",
       "             ('-26744207835626469_short', ''),\n",
       "             ('-3769428450906292372_long', ''),\n",
       "             ('-3769428450906292372_short', ''),\n",
       "             ('2909502194213037723_long', ''),\n",
       "             ('2909502194213037723_short', ''),\n",
       "             ('-4322775683193696877_long', '3452:3902'),\n",
       "             ('-4322775683193696877_short', ''),\n",
       "             ('-1173805886994566979_long', '13277:13421'),\n",
       "             ('-1173805886994566979_short', ''),\n",
       "             ('-498275601085723935_long', ''),\n",
       "             ('-498275601085723935_short', ''),\n",
       "             ('-6256881697851641200_long', ''),\n",
       "             ('-6256881697851641200_short', ''),\n",
       "             ('-2065095633122306018_long', ''),\n",
       "             ('-2065095633122306018_short', ''),\n",
       "             ('-6092597371668069047_long', ''),\n",
       "             ('-6092597371668069047_short', ''),\n",
       "             ('-8012102716327631486_long', ''),\n",
       "             ('-8012102716327631486_short', ''),\n",
       "             ('-6336020651579045965_long', ''),\n",
       "             ('-6336020651579045965_short', ''),\n",
       "             ('1204288827337360876_long', ''),\n",
       "             ('1204288827337360876_short', ''),\n",
       "             ('-2232903166119770615_long', '3443:3657'),\n",
       "             ('-2232903166119770615_short', ''),\n",
       "             ('-5108190336222695693_long', ''),\n",
       "             ('-5108190336222695693_short', ''),\n",
       "             ('-3183208779498643433_long', ''),\n",
       "             ('-3183208779498643433_short', ''),\n",
       "             ('-8352843030477839032_long', ''),\n",
       "             ('-8352843030477839032_short', ''),\n",
       "             ('9188546442463987107_long', ''),\n",
       "             ('9188546442463987107_short', ''),\n",
       "             ('470556784057779418_long', ''),\n",
       "             ('470556784057779418_short', ''),\n",
       "             ('-6330465807440314122_long', '2292:2454'),\n",
       "             ('-6330465807440314122_short', ''),\n",
       "             ('-5368534122572265804_long', ''),\n",
       "             ('-5368534122572265804_short', ''),\n",
       "             ('1207247341423228973_long', '1134:1185'),\n",
       "             ('1207247341423228973_short', ''),\n",
       "             ('-3149569811220675888_long', ''),\n",
       "             ('-3149569811220675888_short', ''),\n",
       "             ('5956049813952195977_long', '2055:2136'),\n",
       "             ('5956049813952195977_short', ''),\n",
       "             ('-8617851792192749121_long', ''),\n",
       "             ('-8617851792192749121_short', ''),\n",
       "             ('-88910826615454643_long', ''),\n",
       "             ('-88910826615454643_short', ''),\n",
       "             ('-8079942120175613865_long', '6229:6679'),\n",
       "             ('-8079942120175613865_short', ''),\n",
       "             ('-7157058681297025181_long', ''),\n",
       "             ('-7157058681297025181_short', ''),\n",
       "             ('-3630115094940729861_long', ''),\n",
       "             ('-3630115094940729861_short', ''),\n",
       "             ('-2331898102646661679_long', '238:391'),\n",
       "             ('-2331898102646661679_short', ''),\n",
       "             ('-924532166209509854_long', ''),\n",
       "             ('-924532166209509854_short', ''),\n",
       "             ('-659381440973847628_long', ''),\n",
       "             ('-659381440973847628_short', ''),\n",
       "             ('-6467472195734766021_long', ''),\n",
       "             ('-6467472195734766021_short', ''),\n",
       "             ('-4748874516746699670_long', ''),\n",
       "             ('-4748874516746699670_short', ''),\n",
       "             ('979380602111616712_long', '21:329'),\n",
       "             ('979380602111616712_short', ''),\n",
       "             ('6357236104337701694_long', '1156:1291'),\n",
       "             ('6357236104337701694_short', ''),\n",
       "             ('718328644908116596_long', ''),\n",
       "             ('718328644908116596_short', ''),\n",
       "             ('-8601880840741158533_long', '1174:1548'),\n",
       "             ('-8601880840741158533_short', ''),\n",
       "             ('-2230117673230036897_long', '2560:2729'),\n",
       "             ('-2230117673230036897_short', ''),\n",
       "             ('-1960481539037275955_long', ''),\n",
       "             ('-1960481539037275955_short', ''),\n",
       "             ('-2978800163239341956_long', ''),\n",
       "             ('-2978800163239341956_short', ''),\n",
       "             ('4915614465302333350_long', ''),\n",
       "             ('4915614465302333350_short', ''),\n",
       "             ('4311493660304100342_long', '1062:1146'),\n",
       "             ('4311493660304100342_short', ''),\n",
       "             ('190406553327512575_long', '64:141'),\n",
       "             ('190406553327512575_short', ''),\n",
       "             ('6213306834749827575_long', '268:352'),\n",
       "             ('6213306834749827575_short', ''),\n",
       "             ('-3050087507574523308_long', '4596:4716'),\n",
       "             ('-3050087507574523308_short', ''),\n",
       "             ('3361755184060826790_long', ''),\n",
       "             ('3361755184060826790_short', ''),\n",
       "             ('-6822872928364142515_long', '1719:2169'),\n",
       "             ('-6822872928364142515_short', ''),\n",
       "             ('-2342217877463848447_long', ''),\n",
       "             ('-2342217877463848447_short', ''),\n",
       "             ('-1718817990360851693_long', ''),\n",
       "             ('-1718817990360851693_short', ''),\n",
       "             ('8766034038731491838_long', ''),\n",
       "             ('8766034038731491838_short', ''),\n",
       "             ('8344425567476614063_long', '236:686'),\n",
       "             ('8344425567476614063_short', ''),\n",
       "             ('-2335900678271962549_long', '8060:8447'),\n",
       "             ('-2335900678271962549_short', ''),\n",
       "             ('6153057216318004474_long', ''),\n",
       "             ('6153057216318004474_short', ''),\n",
       "             ('-4173762245650168251_long', ''),\n",
       "             ('-4173762245650168251_short', ''),\n",
       "             ('726328284631078993_long', ''),\n",
       "             ('726328284631078993_short', ''),\n",
       "             ('-1458914403349801954_long', ''),\n",
       "             ('-1458914403349801954_short', ''),\n",
       "             ('5481448546087645824_long', ''),\n",
       "             ('5481448546087645824_short', ''),\n",
       "             ('6807604168630759478_long', '7659:7742'),\n",
       "             ('6807604168630759478_short', ''),\n",
       "             ('-7975245447510201877_long', ''),\n",
       "             ('-7975245447510201877_short', ''),\n",
       "             ('-4145986654551169542_long', ''),\n",
       "             ('-4145986654551169542_short', ''),\n",
       "             ('-1851374635399017403_long', ''),\n",
       "             ('-1851374635399017403_short', ''),\n",
       "             ('3026246654784946580_long', ''),\n",
       "             ('3026246654784946580_short', ''),\n",
       "             ('-5977600444622102329_long', ''),\n",
       "             ('-5977600444622102329_short', ''),\n",
       "             ('6677203486440593529_long', ''),\n",
       "             ('6677203486440593529_short', ''),\n",
       "             ('-116673467251978251_long', '188:238'),\n",
       "             ('-116673467251978251_short', ''),\n",
       "             ('3143098267219565878_long', ''),\n",
       "             ('3143098267219565878_short', ''),\n",
       "             ('-7912917446275843965_long', '5095:5264'),\n",
       "             ('-7912917446275843965_short', ''),\n",
       "             ('8078004614753233236_long', '6379:6766'),\n",
       "             ('8078004614753233236_short', ''),\n",
       "             ('1699258673018415424_long', ''),\n",
       "             ('1699258673018415424_short', ''),\n",
       "             ('-1790672014856006197_long', '2285:2346'),\n",
       "             ('-1790672014856006197_short', ''),\n",
       "             ('8942226230518515341_long', ''),\n",
       "             ('8942226230518515341_short', ''),\n",
       "             ('-6855163492036335900_long', '24336:24584'),\n",
       "             ('-6855163492036335900_short', ''),\n",
       "             ('-2290200433206917808_long', '175:625'),\n",
       "             ('-2290200433206917808_short', ''),\n",
       "             ('-4245244340292987587_long', ''),\n",
       "             ('-4245244340292987587_short', ''),\n",
       "             ('5441768234501370038_long', '347:483'),\n",
       "             ('5441768234501370038_short', ''),\n",
       "             ('4319712724541914310_long', '699:833'),\n",
       "             ('4319712724541914310_short', ''),\n",
       "             ('529772882906058814_long', '4721:5171'),\n",
       "             ('529772882906058814_short', ''),\n",
       "             ('7067137684942309386_long', '5089:5183'),\n",
       "             ('7067137684942309386_short', ''),\n",
       "             ('-4860485422826284019_long', '1952:2106'),\n",
       "             ('-4860485422826284019_short', ''),\n",
       "             ('107437344188516748_long', ''),\n",
       "             ('107437344188516748_short', ''),\n",
       "             ('-4508421333366241416_long', ''),\n",
       "             ('-4508421333366241416_short', ''),\n",
       "             ('6487750151702115684_long', '2754:2848'),\n",
       "             ('6487750151702115684_short', ''),\n",
       "             ('8450959737287541026_long', ''),\n",
       "             ('8450959737287541026_short', ''),\n",
       "             ('-4617467105261167760_long', ''),\n",
       "             ('-4617467105261167760_short', ''),\n",
       "             ('-7893720973221749452_long', ''),\n",
       "             ('-7893720973221749452_short', ''),\n",
       "             ('3086249202080695686_long', ''),\n",
       "             ('3086249202080695686_short', ''),\n",
       "             ('7755787408066760818_long', ''),\n",
       "             ('7755787408066760818_short', ''),\n",
       "             ('8155484069063481455_long', ''),\n",
       "             ('8155484069063481455_short', ''),\n",
       "             ('-4897020598228240921_long', ''),\n",
       "             ('-4897020598228240921_short', ''),\n",
       "             ('4279738737380736656_long', ''),\n",
       "             ('4279738737380736656_short', ''),\n",
       "             ('-59591452250878333_long', '265:343'),\n",
       "             ('-59591452250878333_short', ''),\n",
       "             ('-5174354218669872287_long', ''),\n",
       "             ('-5174354218669872287_short', ''),\n",
       "             ('7770117184227306343_long', ''),\n",
       "             ('7770117184227306343_short', ''),\n",
       "             ('-2135428989104836174_long', '1216:1406'),\n",
       "             ('-2135428989104836174_short', ''),\n",
       "             ('512942171744482497_long', ''),\n",
       "             ('512942171744482497_short', ''),\n",
       "             ('6833899876961014698_long', ''),\n",
       "             ('6833899876961014698_short', ''),\n",
       "             ('7312212568817071125_long', '2018:2468'),\n",
       "             ('7312212568817071125_short', ''),\n",
       "             ('5418729114938856534_long', ''),\n",
       "             ('5418729114938856534_short', ''),\n",
       "             ('4860431881544546745_long', ''),\n",
       "             ('4860431881544546745_short', ''),\n",
       "             ('-23901073947973600_long', '306:365'),\n",
       "             ('-23901073947973600_short', ''),\n",
       "             ('-4159043308971817559_long', '14:372'),\n",
       "             ('-4159043308971817559_short', ''),\n",
       "             ('3126997404306158462_long', ''),\n",
       "             ('3126997404306158462_short', ''),\n",
       "             ('-5337738362122628940_long', ''),\n",
       "             ('-5337738362122628940_short', ''),\n",
       "             ('1830952957837313980_long', ''),\n",
       "             ('1830952957837313980_short', ''),\n",
       "             ('-2066721157005376071_long', '3294:3529'),\n",
       "             ('-2066721157005376071_short', ''),\n",
       "             ('8188685362873477090_long', '399:506'),\n",
       "             ('8188685362873477090_short', ''),\n",
       "             ('6286084877144579335_long', ''),\n",
       "             ('6286084877144579335_short', ''),\n",
       "             ('7996492172224681904_long', '259:358'),\n",
       "             ('7996492172224681904_short', ''),\n",
       "             ('-2382015829568615705_long', '1523:1964'),\n",
       "             ('-2382015829568615705_short', ''),\n",
       "             ('-1363487503998292562_long', '21:150'),\n",
       "             ('-1363487503998292562_short', ''),\n",
       "             ('-5829418016047917429_long', '1545:1604'),\n",
       "             ('-5829418016047917429_short', ''),\n",
       "             ('-7019824872367131740_long', ''),\n",
       "             ('-7019824872367131740_short', ''),\n",
       "             ('-1567167724192142377_long', ''),\n",
       "             ('-1567167724192142377_short', ''),\n",
       "             ('1319440920141041764_long', '4143:4249'),\n",
       "             ('1319440920141041764_short', ''),\n",
       "             ('6310714729623780383_long', ''),\n",
       "             ('6310714729623780383_short', ''),\n",
       "             ('5697078122347551736_long', ''),\n",
       "             ('5697078122347551736_short', ''),\n",
       "             ('-498216869850038846_long', '2144:2361'),\n",
       "             ('-498216869850038846_short', ''),\n",
       "             ('8828691553648112177_long', ''),\n",
       "             ('8828691553648112177_short', ''),\n",
       "             ('-4777352876260495340_long', ''),\n",
       "             ('-4777352876260495340_short', ''),\n",
       "             ('2477807257046472472_long', '79:147'),\n",
       "             ('2477807257046472472_short', ''),\n",
       "             ('-3013417941434408220_long', ''),\n",
       "             ('-3013417941434408220_short', ''),\n",
       "             ('-1282307916188794339_long', ''),\n",
       "             ('-1282307916188794339_short', ''),\n",
       "             ('-4125374224274459807_long', '368:427'),\n",
       "             ('-4125374224274459807_short', ''),\n",
       "             ('2728228414906581783_long', '1795:2245'),\n",
       "             ('2728228414906581783_short', ''),\n",
       "             ('-521386453811823583_long', '1369:1468'),\n",
       "             ('-521386453811823583_short', ''),\n",
       "             ('2167498496559544446_long', '6801:7025'),\n",
       "             ('2167498496559544446_short', ''),\n",
       "             ('1061123991680590844_long', ''),\n",
       "             ('1061123991680590844_short', ''),\n",
       "             ('2165432788661190020_long', '1109:1280'),\n",
       "             ('2165432788661190020_short', ''),\n",
       "             ('2538446403077572144_long', ''),\n",
       "             ('2538446403077572144_short', ''),\n",
       "             ('2248522536111672263_long', ''),\n",
       "             ('2248522536111672263_short', ''),\n",
       "             ('-8759335434692901364_long', '2689:3139'),\n",
       "             ('-8759335434692901364_short', ''),\n",
       "             ('-691098024792500533_long', '278:365'),\n",
       "             ('-691098024792500533_short', ''),\n",
       "             ('8163047620788351810_long', ''),\n",
       "             ('8163047620788351810_short', ''),\n",
       "             ('4635425600222748685_long', '285:567'),\n",
       "             ('4635425600222748685_short', ''),\n",
       "             ('-6644780095764945803_long', ''),\n",
       "             ('-6644780095764945803_short', ''),\n",
       "             ('4402487527582928244_long', ''),\n",
       "             ('4402487527582928244_short', ''),\n",
       "             ('-5571851459920818254_long', '374:483'),\n",
       "             ('-5571851459920818254_short', ''),\n",
       "             ('8747456200740322758_long', ''),\n",
       "             ('8747456200740322758_short', ''),\n",
       "             ('-5122137412557650065_long', ''),\n",
       "             ('-5122137412557650065_short', ''),\n",
       "             ('1943964004035602678_long', ''),\n",
       "             ('1943964004035602678_short', ''),\n",
       "             ('6527613691925251535_long', '1166:1315'),\n",
       "             ('6527613691925251535_short', ''),\n",
       "             ('2105742558472154903_long', ''),\n",
       "             ('2105742558472154903_short', ''),\n",
       "             ('4058047364107136758_long', ''),\n",
       "             ('4058047364107136758_short', ''),\n",
       "             ('6522755687197646934_long', '164:427'),\n",
       "             ('6522755687197646934_short', '')])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['-1258974036110822789_long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{'example_id': k, 'PredictionString': v} for k, v in submission.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.PredictionString.astype(bool).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1258974036110822789"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst['meta'].metadata['candidate_start_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1__2'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}__{}'.format(*(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(params['validation_data_path']) as reader:\n",
    "    for line in reader:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document_text', 'long_answer_candidates', 'question_text', 'annotations', 'document_url', 'example_id'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_token': 16, 'top_level': True, 'end_token': 67},\n",
       " {'start_token': 17, 'top_level': False, 'end_token': 66},\n",
       " {'start_token': 79, 'top_level': True, 'end_token': 118},\n",
       " {'start_token': 118, 'top_level': True, 'end_token': 381},\n",
       " {'start_token': 381, 'top_level': True, 'end_token': 497},\n",
       " {'start_token': 497, 'top_level': True, 'end_token': 607},\n",
       " {'start_token': 607, 'top_level': True, 'end_token': 678},\n",
       " {'start_token': 907, 'top_level': True, 'end_token': 963},\n",
       " {'start_token': 971, 'top_level': True, 'end_token': 1084},\n",
       " {'start_token': 1084, 'top_level': True, 'end_token': 1174},\n",
       " {'start_token': 1174, 'top_level': True, 'end_token': 1316},\n",
       " {'start_token': 1339, 'top_level': True, 'end_token': 1637},\n",
       " {'start_token': 1637, 'top_level': True, 'end_token': 1823},\n",
       " {'start_token': 1830, 'top_level': True, 'end_token': 1903},\n",
       " {'start_token': 1903, 'top_level': True, 'end_token': 2030},\n",
       " {'start_token': 2030, 'top_level': True, 'end_token': 2181},\n",
       " {'start_token': 2181, 'top_level': True, 'end_token': 2370},\n",
       " {'start_token': 2370, 'top_level': True, 'end_token': 2459},\n",
       " {'start_token': 2459, 'top_level': True, 'end_token': 2598},\n",
       " {'start_token': 2460, 'top_level': False, 'end_token': 2597},\n",
       " {'start_token': 2598, 'top_level': True, 'end_token': 2686},\n",
       " {'start_token': 2686, 'top_level': True, 'end_token': 2785},\n",
       " {'start_token': 2687, 'top_level': False, 'end_token': 2784},\n",
       " {'start_token': 2785, 'top_level': True, 'end_token': 2975},\n",
       " {'start_token': 2975, 'top_level': True, 'end_token': 3074},\n",
       " {'start_token': 3074, 'top_level': True, 'end_token': 3186},\n",
       " {'start_token': 3075, 'top_level': False, 'end_token': 3185},\n",
       " {'start_token': 3195, 'top_level': True, 'end_token': 3353},\n",
       " {'start_token': 3361, 'top_level': True, 'end_token': 3391},\n",
       " {'start_token': 3391, 'top_level': True, 'end_token': 3470},\n",
       " {'start_token': 3470, 'top_level': True, 'end_token': 3535},\n",
       " {'start_token': 3535, 'top_level': True, 'end_token': 3682},\n",
       " {'start_token': 3682, 'top_level': True, 'end_token': 3860},\n",
       " {'start_token': 3860, 'top_level': True, 'end_token': 4043},\n",
       " {'start_token': 4043, 'top_level': True, 'end_token': 4063},\n",
       " {'start_token': 4078, 'top_level': True, 'end_token': 4165},\n",
       " {'start_token': 4165, 'top_level': True, 'end_token': 4271},\n",
       " {'start_token': 4271, 'top_level': True, 'end_token': 4290},\n",
       " {'start_token': 4290, 'top_level': True, 'end_token': 4321},\n",
       " {'start_token': 4291, 'top_level': False, 'end_token': 4302},\n",
       " {'start_token': 4302, 'top_level': False, 'end_token': 4320},\n",
       " {'start_token': 4321, 'top_level': True, 'end_token': 4336},\n",
       " {'start_token': 4336, 'top_level': True, 'end_token': 4376},\n",
       " {'start_token': 4376, 'top_level': True, 'end_token': 4523},\n",
       " {'start_token': 4523, 'top_level': True, 'end_token': 4652},\n",
       " {'start_token': 4652, 'top_level': True, 'end_token': 4827},\n",
       " {'start_token': 4827, 'top_level': True, 'end_token': 4940},\n",
       " {'start_token': 4940, 'top_level': True, 'end_token': 5047},\n",
       " {'start_token': 5047, 'top_level': True, 'end_token': 5183},\n",
       " {'start_token': 5183, 'top_level': True, 'end_token': 5254},\n",
       " {'start_token': 5254, 'top_level': True, 'end_token': 5335},\n",
       " {'start_token': 5335, 'top_level': True, 'end_token': 5374},\n",
       " {'start_token': 5403, 'top_level': True, 'end_token': 5487},\n",
       " {'start_token': 5493, 'top_level': True, 'end_token': 5548},\n",
       " {'start_token': 5548, 'top_level': True, 'end_token': 5626},\n",
       " {'start_token': 5626, 'top_level': True, 'end_token': 5744},\n",
       " {'start_token': 5744, 'top_level': True, 'end_token': 5793},\n",
       " {'start_token': 5793, 'top_level': True, 'end_token': 5822},\n",
       " {'start_token': 5822, 'top_level': True, 'end_token': 5857},\n",
       " {'start_token': 5857, 'top_level': True, 'end_token': 5923},\n",
       " {'start_token': 5923, 'top_level': True, 'end_token': 6017},\n",
       " {'start_token': 6017, 'top_level': True, 'end_token': 6059},\n",
       " {'start_token': 6059, 'top_level': True, 'end_token': 6120},\n",
       " {'start_token': 6120, 'top_level': True, 'end_token': 6185},\n",
       " {'start_token': 6197, 'top_level': True, 'end_token': 6226},\n",
       " {'start_token': 6226, 'top_level': True, 'end_token': 6260},\n",
       " {'start_token': 6276, 'top_level': True, 'end_token': 6331},\n",
       " {'start_token': 6331, 'top_level': True, 'end_token': 6382},\n",
       " {'start_token': 6382, 'top_level': True, 'end_token': 6419},\n",
       " {'start_token': 6419, 'top_level': True, 'end_token': 6503},\n",
       " {'start_token': 6503, 'top_level': True, 'end_token': 6533},\n",
       " {'start_token': 6533, 'top_level': True, 'end_token': 6554},\n",
       " {'start_token': 6554, 'top_level': True, 'end_token': 6616},\n",
       " {'start_token': 6616, 'top_level': True, 'end_token': 6651},\n",
       " {'start_token': 6667, 'top_level': True, 'end_token': 6728},\n",
       " {'start_token': 6728, 'top_level': True, 'end_token': 6815},\n",
       " {'start_token': 6815, 'top_level': True, 'end_token': 6868},\n",
       " {'start_token': 6868, 'top_level': True, 'end_token': 6906},\n",
       " {'start_token': 6906, 'top_level': True, 'end_token': 6960},\n",
       " {'start_token': 6960, 'top_level': True, 'end_token': 7045},\n",
       " {'start_token': 7045, 'top_level': True, 'end_token': 7250},\n",
       " {'start_token': 7250, 'top_level': True, 'end_token': 7354},\n",
       " {'start_token': 7376, 'top_level': True, 'end_token': 7501},\n",
       " {'start_token': 7501, 'top_level': True, 'end_token': 7537},\n",
       " {'start_token': 7546, 'top_level': True, 'end_token': 7771},\n",
       " {'start_token': 7783, 'top_level': True, 'end_token': 7908},\n",
       " {'start_token': 7908, 'top_level': True, 'end_token': 7959},\n",
       " {'start_token': 7959, 'top_level': True, 'end_token': 8141},\n",
       " {'start_token': 8141, 'top_level': True, 'end_token': 8291},\n",
       " {'start_token': 8291, 'top_level': True, 'end_token': 8485},\n",
       " {'start_token': 8485, 'top_level': True, 'end_token': 8597},\n",
       " {'start_token': 8611, 'top_level': True, 'end_token': 8652},\n",
       " {'start_token': 8652, 'top_level': True, 'end_token': 8740},\n",
       " {'start_token': 8740, 'top_level': True, 'end_token': 8757},\n",
       " {'start_token': 8757, 'top_level': True, 'end_token': 8819},\n",
       " {'start_token': 8758, 'top_level': False, 'end_token': 8801},\n",
       " {'start_token': 8801, 'top_level': False, 'end_token': 8818},\n",
       " {'start_token': 8819, 'top_level': True, 'end_token': 8926},\n",
       " {'start_token': 8936, 'top_level': True, 'end_token': 8998},\n",
       " {'start_token': 8998, 'top_level': True, 'end_token': 9125},\n",
       " {'start_token': 9125, 'top_level': True, 'end_token': 9206},\n",
       " {'start_token': 9220, 'top_level': True, 'end_token': 9279},\n",
       " {'start_token': 9287, 'top_level': True, 'end_token': 9327},\n",
       " {'start_token': 9327, 'top_level': True, 'end_token': 9490},\n",
       " {'start_token': 9496, 'top_level': True, 'end_token': 9554},\n",
       " {'start_token': 9554, 'top_level': True, 'end_token': 9718},\n",
       " {'start_token': 9718, 'top_level': True, 'end_token': 9783},\n",
       " {'start_token': 9783, 'top_level': True, 'end_token': 9824},\n",
       " {'start_token': 9838, 'top_level': True, 'end_token': 9874},\n",
       " {'start_token': 9839, 'top_level': False, 'end_token': 9849},\n",
       " {'start_token': 9842, 'top_level': False, 'end_token': 9848},\n",
       " {'start_token': 9865, 'top_level': False, 'end_token': 9873},\n",
       " {'start_token': 9881, 'top_level': True, 'end_token': 9915},\n",
       " {'start_token': 9882, 'top_level': False, 'end_token': 9891},\n",
       " {'start_token': 9891, 'top_level': False, 'end_token': 9899},\n",
       " {'start_token': 9899, 'top_level': False, 'end_token': 9907},\n",
       " {'start_token': 9907, 'top_level': False, 'end_token': 9914},\n",
       " {'start_token': 9922, 'top_level': True, 'end_token': 9986},\n",
       " {'start_token': 9923, 'top_level': False, 'end_token': 9932},\n",
       " {'start_token': 9932, 'top_level': False, 'end_token': 9942},\n",
       " {'start_token': 9942, 'top_level': False, 'end_token': 9948},\n",
       " {'start_token': 9948, 'top_level': False, 'end_token': 9955},\n",
       " {'start_token': 9959, 'top_level': False, 'end_token': 9966},\n",
       " {'start_token': 9966, 'top_level': False, 'end_token': 9985},\n",
       " {'start_token': 9993, 'top_level': True, 'end_token': 10063},\n",
       " {'start_token': 9994, 'top_level': False, 'end_token': 10007},\n",
       " {'start_token': 10007, 'top_level': False, 'end_token': 10020},\n",
       " {'start_token': 10020, 'top_level': False, 'end_token': 10035},\n",
       " {'start_token': 10035, 'top_level': False, 'end_token': 10045},\n",
       " {'start_token': 10045, 'top_level': False, 'end_token': 10054},\n",
       " {'start_token': 10054, 'top_level': False, 'end_token': 10062},\n",
       " {'start_token': 10070, 'top_level': True, 'end_token': 10123},\n",
       " {'start_token': 10089, 'top_level': False, 'end_token': 10094},\n",
       " {'start_token': 10098, 'top_level': False, 'end_token': 10105},\n",
       " {'start_token': 10105, 'top_level': False, 'end_token': 10110},\n",
       " {'start_token': 10114, 'top_level': False, 'end_token': 10119},\n",
       " {'start_token': 10133, 'top_level': True, 'end_token': 11107},\n",
       " {'start_token': 10134, 'top_level': False, 'end_token': 10192},\n",
       " {'start_token': 10192, 'top_level': False, 'end_token': 10265},\n",
       " {'start_token': 10265, 'top_level': False, 'end_token': 10309},\n",
       " {'start_token': 10309, 'top_level': False, 'end_token': 10370},\n",
       " {'start_token': 10370, 'top_level': False, 'end_token': 10447},\n",
       " {'start_token': 10447, 'top_level': False, 'end_token': 10657},\n",
       " {'start_token': 10657, 'top_level': False, 'end_token': 10685},\n",
       " {'start_token': 10685, 'top_level': False, 'end_token': 10710},\n",
       " {'start_token': 10710, 'top_level': False, 'end_token': 10769},\n",
       " {'start_token': 10769, 'top_level': False, 'end_token': 10805},\n",
       " {'start_token': 10805, 'top_level': False, 'end_token': 10846},\n",
       " {'start_token': 10846, 'top_level': False, 'end_token': 10872},\n",
       " {'start_token': 10872, 'top_level': False, 'end_token': 10915},\n",
       " {'start_token': 10915, 'top_level': False, 'end_token': 10944},\n",
       " {'start_token': 10944, 'top_level': False, 'end_token': 11041},\n",
       " {'start_token': 11041, 'top_level': False, 'end_token': 11106}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line['long_answer_candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.74120527e-12, 3.58257781e-12, 2.27677772e-12, 4.98013714e-11,\n",
       "       1.75781449e-12, 3.93584228e-11, 2.65977018e-10, 2.47831053e-12,\n",
       "       1.48078882e-10, 1.00000000e+00, 5.00546566e-12, 2.54231983e-11,\n",
       "       2.72890814e-13, 7.21567988e-13, 1.86188386e-13, 8.06734440e-14,\n",
       "       1.38707229e-13, 2.50405301e-13, 1.61096356e-13, 2.14020072e-13,\n",
       "       1.43250090e-13, 5.75047226e-13, 1.77148538e-13, 1.84621090e-13,\n",
       "       2.11917967e-13, 2.64569508e-13, 9.17822784e-13, 1.50097315e-13,\n",
       "       1.70493082e-13, 8.20020321e-14, 1.00831520e-13, 1.08939645e-13,\n",
       "       2.11119189e-09, 1.27482186e-13, 1.80516761e-13, 1.32638651e-13,\n",
       "       7.32685017e-13, 6.41841940e-13, 1.78506610e-13, 1.64872605e-13,\n",
       "       1.49719890e-13, 1.15443056e-13, 3.35153482e-13, 7.36383719e-13,\n",
       "       1.59665656e-13, 5.13281431e-12, 6.47599108e-14, 1.55645164e-13,\n",
       "       2.10130497e-13, 1.35983144e-13, 2.09678087e-13, 2.71303759e-13,\n",
       "       1.35278968e-13, 1.80635942e-13, 9.07738579e-14, 2.36311052e-13,\n",
       "       8.60806042e-14, 1.53300224e-13, 3.96085379e-14, 1.39254039e-10,\n",
       "       2.54370933e-13, 7.60577853e-14, 2.28954594e-12, 2.86530917e-13,\n",
       "       9.91177192e-13, 1.12340320e-13, 1.89602227e-13, 1.34226799e-12,\n",
       "       2.30073827e-13, 2.01402900e-13, 2.36674151e-13, 1.61017488e-12,\n",
       "       3.74780339e-13, 2.78607676e-13, 4.73873158e-14, 7.40312420e-14,\n",
       "       5.00771435e-14, 6.31442598e-14, 1.43780306e-13, 1.80950768e-13,\n",
       "       2.86127323e-13, 6.66950287e-14, 1.35060339e-13, 7.63085884e-14,\n",
       "       3.48503805e-13, 3.25895642e-13, 1.79118127e-13, 2.80867289e-13,\n",
       "       1.04444007e-13, 1.14332507e-13, 3.86560629e-13, 2.94698592e-13,\n",
       "       1.41404941e-13, 1.10644431e-13, 1.45368711e-12, 5.78536581e-14,\n",
       "       1.81957558e-13, 1.25704853e-13, 8.64002067e-14, 1.62752055e-13,\n",
       "       7.70586123e-14, 1.47830316e-13, 1.39321036e-13, 6.16583539e-14,\n",
       "       8.70268823e-14, 1.55629727e-13, 1.43268942e-13, 3.17629834e-14,\n",
       "       7.33972605e-11, 5.55464745e-13, 1.50941081e-13, 3.45903861e-13,\n",
       "       4.08233343e-13, 3.42351439e-14, 6.38953192e-13, 1.44448255e-13,\n",
       "       1.50049230e-13, 1.01192573e-13, 2.62430512e-13, 1.06832152e-13,\n",
       "       1.38463771e-13, 1.46427209e-13, 1.53308112e-13, 2.01282703e-13,\n",
       "       2.41543845e-13, 1.73278736e-13, 1.64283409e-13, 2.06987178e-13,\n",
       "       1.33547843e-11, 1.26703091e-13, 1.52638495e-13, 4.30826029e-13,\n",
       "       7.08397533e-13, 1.25090883e-13, 1.43765222e-13, 8.22449747e-14,\n",
       "       3.45213116e-13, 3.46250230e-14, 3.69331640e-14, 8.63348089e-14,\n",
       "       4.95773670e-13, 1.06347677e-13, 6.80617672e-13, 1.15027860e-13,\n",
       "       1.50119649e-13, 2.82272740e-13, 5.56790365e-14, 7.26551794e-14,\n",
       "       3.53831954e-13, 5.72597457e-14, 6.74246358e-13, 2.11620286e-13,\n",
       "       6.97380250e-13, 1.29500618e-13, 2.24693175e-13, 1.20166179e-13,\n",
       "       3.68325840e-13, 7.92834765e-14, 2.06441784e-14, 5.15950943e-13,\n",
       "       2.48993182e-13, 9.80708353e-13, 1.61234063e-13, 1.08653897e-13,\n",
       "       5.34519260e-14, 1.81787582e-13, 7.08567455e-14, 9.14258022e-14,\n",
       "       3.37515497e-13, 1.78094085e-13, 1.91009860e-13, 3.66211700e-13,\n",
       "       2.02822297e-13, 8.38485572e-14, 5.07057199e-14, 9.28949571e-14,\n",
       "       4.90234006e-14, 3.78465976e-14, 1.94138783e-14, 6.87600747e-14,\n",
       "       1.17328131e-13, 4.19739452e-14, 5.53138535e-14, 4.16571549e-14,\n",
       "       3.27892715e-13, 8.86293195e-14, 6.63070376e-10, 6.87472201e-14,\n",
       "       6.32127068e-14, 2.70624641e-13, 2.34721164e-14, 8.31628874e-14,\n",
       "       5.48687445e-14, 5.56428655e-13, 1.01755986e-13, 1.09258644e-13,\n",
       "       6.09540765e-14, 1.08592775e-13, 1.76084042e-13, 3.16147960e-13,\n",
       "       4.41915757e-14, 5.72240484e-14, 8.48471345e-14, 5.51224105e-13,\n",
       "       4.81368621e-14, 8.56227659e-14, 1.70638189e-13, 5.44868377e-14,\n",
       "       3.27685768e-13, 1.43538366e-13, 6.17865893e-13, 9.56647752e-14,\n",
       "       1.92664813e-13, 2.21974200e-13, 4.08869783e-14, 3.72950759e-12,\n",
       "       5.79364776e-14, 8.70997813e-14, 8.99683838e-14, 2.52733896e-13,\n",
       "       6.01070165e-14, 7.29339752e-14, 3.99785700e-13, 5.67260377e-13,\n",
       "       3.72363951e-14, 4.91042550e-14, 3.88516476e-13, 7.63398879e-14,\n",
       "       1.52752377e-13, 9.03639346e-14, 1.47020213e-13, 1.34459392e-13,\n",
       "       7.05710785e-14, 1.98488551e-13, 7.58182173e-14, 8.65233991e-14,\n",
       "       1.76245317e-13, 1.33387577e-13, 1.60650207e-13, 6.15307704e-14,\n",
       "       1.08232976e-13, 1.06543396e-13, 9.40340809e-14, 1.43257192e-13,\n",
       "       4.29716247e-14, 3.26882531e-12, 9.60958133e-14, 7.95044933e-12,\n",
       "       8.16575675e-14, 3.57347398e-12, 5.74691661e-14, 1.99925932e-13,\n",
       "       5.86731347e-13, 1.63968253e-12, 2.81769643e-14, 2.53343592e-12,\n",
       "       4.91131766e-13, 2.41378505e-13, 9.32367031e-13, 3.43570279e-13,\n",
       "       2.64568640e-12, 1.24575697e-12, 1.67808543e-13, 2.21759649e-13,\n",
       "       1.71135567e-13, 7.22268518e-14, 2.84355357e-13, 2.17144648e-13,\n",
       "       4.84841557e-14, 1.14963825e-13, 6.15975283e-12, 2.19278822e-14,\n",
       "       5.17631321e-14], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['start_logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fedc3ab9ef0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(res['start_logits'].reshape(1, -1), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
