{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common import Params\n",
    "from allennlp.data import DatasetReader\n",
    "from allennlp.data.dataset import Batch\n",
    "from allennlp.data.iterators import BasicIterator\n",
    "\n",
    "from allennlp.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/emelyanov-yi/PycharmProjects/kaggle_tf2_qa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import NaturalQuestionsModel, NaturalQuestionsDatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/home/emelyanov-yi/models/tf2_qa/init_fix_softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params.from_file(prefix + '/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load(params, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = DatasetReader.from_params(params['dataset_reader'].duplicate())\n",
    "reader._downsample_negative = 1.1\n",
    "reader._downsample_all = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_gen = reader.read(params['validation_data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inst in instances_gen:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch([inst])\n",
    "batch.index_instances(model.vocab)\n",
    "res = model.forward_on_instance(inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['start_logits', 'end_logits', 'label_logits', 'mask', 'meta', 'loss', 'label_loss', 'qa_loss'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.update(**res['meta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['start_logits', 'end_logits', 'label_logits', 'mask', 'meta', 'loss', 'label_loss', 'qa_loss', 'example_id', 'candidate_start_token', 'text', 'query', 'offset'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t context: TextField of length 62 with text: \n",
      " \t\t[[CLS], the, name, of, the, separatist, political, party, in, quebec, [SEP], <Table>, <Tr>, <Td>,\n",
      "\t\t</Td>, <Td>, This, article, needs, additional, citations, for, verification, ., Please, help,\n",
      "\t\timprove, this, article, by, adding, citations, to, reliable, sources, ., Unsourced, material, may,\n",
      "\t\tbe, challenged, and, removed, ., (, April, 2010, ), (, Learn, how, and, when, to, remove, this,\n",
      "\t\ttemplate, message, ), </Td>, </Tr>, </Table>]\n",
      " \t\tand TokenIndexers : {'tokens': 'PretrainedBertIndexer'} \n",
      " \t meta: MetadataField (print field.metadata to see specific information). \n",
      " \t answer_start: IndexField with index: 10. \n",
      " \t answer_end: IndexField with index: 10. \n",
      " \t answer_label: LabelField with label: not_relevant in namespace: 'answer_labels'.' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From predictions for all paragraphs to one document-level prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [00:16, 13.40it/s]Too many wordpieces, truncating sequence. If you would like a sliding window, set `truncate_long_sequences` to False.The offending input was: ['[CLS]', 'the', 'name', 'of', 'the', 'separatist', 'political', 'party', 'in', 'quebec', '[SEP]', '<Ul>', '<Li>', 'Richard', 'Rohmer', \"'s\", 'novel', 'Separation', '(', '1976', ')', 'was', 'turned', 'into', 'a', 'TV', '-', 'movie', 'for', 'CTV', 'Television', 'in', '1977', '.', 'In', 'the', 'movie', ',', 'the', 'Parti', 'Québécois', 'has', 'formed', 'the', 'government', 'of', 'Quebec', 'but', 'Premier', 'Gaston', 'Belisle', 'has', 'repeatedly', 'put', 'off', 'its', 'promise', 'to', 'hold', 'a', 'referendum', '.', 'International', 'politics', 'forces', 'Belisle', \"'s\", 'hand', '.', '</Li>', '<Li>', 'In', 'the', 'mid-1980s', ',', 'a', 'second', 'movie', ',', 'Quebec', '-', 'Canada', '1995', ',', 'depicts', 'a', 'meeting', 'between', 'the', 'president', 'of', 'Quebec', 'and', 'the', 'prime', 'minister', 'of', 'Canada', 'to', 'discuss', 'a', 'crisis', 'involving', 'Quebec', 'military', 'occupations', 'of', 'parts', 'of', 'Ontario', 'and', 'New', 'Brunswick', '.', 'Canada', \"'s\", 'armed', 'forces', 'are', 'stretched', 'thin', 'with', 'peacekeepers', 'in', 'such', 'varied', 'places', 'as', 'the', 'Falkland', 'Islands', '(', 'with', '``', 'Lady', 'Goosegreen', \"''\", 'being', 'Margaret', 'Thatcher', ')', '.', '</Li>', '<Li>', 'William', 'Weintraub', \"'s\", 'satirical', '1979', 'novel', 'The', 'Underdogs', 'provoked', 'controversy', 'by', 'imagining', 'a', 'future', 'Quebec', 'in', 'which', 'English', '-', 'speakers', 'were', 'an', 'oppressed', 'minority', ',', 'complete', 'with', 'a', 'violent', 'resistance', 'movement', '.', 'One', 'planned', 'stage', 'version', 'was', 'cancelled', 'before', 'its', 'premiere', '.', '</Li>', '<Li>', 'Clive', 'Cussler', \"'s\", '1984', 'novel', 'Night', 'Probe', '!', 'is', 'set', 'against', 'a', 'fictional', 'attempt', 'at', 'secession', 'in', 'the', 'late', '1980s', '.', 'Rights', 'to', 'newly', 'discovered', 'oil', 'resources', 'in', 'Ungava', 'Bay', ',', 'discovered', 'as', 'Quebec', 'moves', 'to', 'secede', ',', 'clash', 'with', 'the', 'ramifications', 'of', 'a', 'rediscovered', 'secret', 'treaty', 'negotiated', 'between', 'the', 'U.K.', 'and', 'U.S.', 'governments', 'during', 'World', 'War', 'I', '.', '</Li>', '<Li>', 'David', 'Foster', 'Wallace', \"'s\", 'novel', 'Infinite', 'Jest', 'includes', 'both', 'real', 'and', 'fictional', 'Québécois', 'separatist', 'movements', 'as', 'integral', 'to', 'the', 'plot', '.', 'In', 'the', 'story', ',', 'the', 'United', 'States', 'has', 'merged', 'with', 'Canada', 'and', 'Mexico', 'to', 'form', 'the', 'Organization', 'of', 'North', 'American', 'Nations', '(', 'ONAN', ')', '.', 'Wheelchair', '-', 'bound', 'Quebec', 'separatists', 'use', 'a', 'video', 'so', 'entertaining', 'it', 'leads', 'to', 'death', 'to', 'accomplish', 'their', 'goals', 'of', 'both', 'Quebec', 'independence', 'and', 'the', 'end', 'of', 'the', 'ONAN', '.', '</Li>', '<Li>', 'In', 'the', 'Southern', 'Victory', 'Series', 'of', 'alternate', 'history', 'novels', 'by', 'Harry', 'Turtledove', ',', 'Quebec', 'becomes', 'a', 'separate', 'nation', 'during', 'the', 'First', 'Great', 'War', '(', 'an', 'alternative', 'World', 'War', 'I', ')', ',', 'in', 'which', 'the', 'United', 'States', 'defeats', 'Canada', ',', 'the', 'United', 'Kingdom', 'and', 'the', 'other', 'Entente', 'Powers', '(', 'including', 'the', 'Confederate', 'States', 'of', 'America', ')', ';', 'upon', 'its', 'founding', ',', 'the', 'Republic', 'is', 'officially', 'recognised', 'only', 'by', 'the', 'United', 'States', ',', 'Germany', ',', 'Austria', '-', 'Hungary', ',', 'Bulgaria', ',', 'the', 'Ottoman', 'Empire', ',', 'Poland', ',', 'Ukraine', ',', 'Italy', 'and', 'the', 'Netherlands', '.', 'Since', 'the', 'United', 'States', 'organized', 'this', 'separation', 'to', 'weaken', 'Anglophone', 'Canada', '(', 'and', 'the', 'UK', 'by', 'extension', ')', 'and', 'to', 'aid', 'in', 'the', 'post-war', 'occupation', 'of', 'Canada', ',', 'the', 'Republic', 'of', 'Quebec', 'operated', 'as', 'a', 'client', 'state', 'of', 'the', 'United', 'States', ',', 'rather'].To avoid polluting your logs we will not warn about this again.\n",
      "20358it [40:10,  8.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3ba0a4f0ace3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_on_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mforward_on_instance\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensors\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minto\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mremove\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_on_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     def forward_on_instances(self,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mforward_on_instances\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0minstance_separated_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/kaggle_tf2_qa/src/nq_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context, answer_label, answer_start, answer_end, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Answer start ans answer ends must be provided simultaneously'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_field_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B , L]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B , N , E]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text_field_input, num_wrapping_dims, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     tensors = [(text_field_input[indexer_key] if indexer_key is not None else None)\n\u001b[1;32m    117\u001b[0m                                for indexer_key in indexer_map]\n\u001b[0;32m--> 118\u001b[0;31m                     \u001b[0mtoken_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     tensors = {\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/allennlp/modules/token_embedders/bert_token_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, offsets, token_type_ids)\u001b[0m\n\u001b[1;32m    173\u001b[0m         all_encoder_layers, _ = self.bert_model(input_ids=util.combine_initial_dims(input_ids),\n\u001b[1;32m    174\u001b[0m                                                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_initial_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                                                 attention_mask=util.combine_initial_dims(input_mask))\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mInitializes\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m \u001b[0mby\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mScriptModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"python.nn_module\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results: List[Dict] = []\n",
    "for inst in tqdm(instances_gen):\n",
    "    batch = Batch([inst])\n",
    "    batch.index_instances(model.vocab)\n",
    "    res = model.forward_on_instance(inst)\n",
    "    \n",
    "    res.update(**res['meta'])\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "docwise_results = defaultdict(list)\n",
    "for res in results:\n",
    "    docwise_results[res['example_id']].append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = model.vocab  # for convenience ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['offset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/161 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions: Dict[str, Tuple] = {}\n",
    "    \n",
    "for doc_id, all_results in tqdm(docwise_results.items()):\n",
    "    long_answer_candidate = None\n",
    "    for result in all_results:\n",
    "        predicted_label = vocab.get_token_from_index(result['label_logits'].argmax(), namespace='answer_labels')\n",
    "        if predicted_label in ['YES', 'NO']:\n",
    "            # when we predict yes-no answer, we use current paragraph as long answer and do not check other paragraphs at all\n",
    "            # TODO: get best match based on logits\n",
    "            predictions[doc_id] = ((result['candidate_start_token'], result['candidate_start_token'] + len(result['document'])), predicted_label)\n",
    "            break\n",
    "        elif predicted_label == 'NONE':\n",
    "            # paragraph is at least relevant, save it if there will be no other such prediction in the future\n",
    "            # get predicted short answer (if exists)\n",
    "            offset = result['offset']\n",
    "            short_answer_start = res['start_logits'].argmax() - offset\n",
    "            short_answer_end = res['end_logits'].argmax() - offset\n",
    "            if short_answer_end >= short_answer_start \\\n",
    "                and short_answer_start >= 0:\n",
    "                # found good short answer, break\n",
    "                predictions[doc_id] = (long_answer_candidate, (short_answer_start, short_answer_end))\n",
    "                break\n",
    "            else:\n",
    "                long_answer_candidate = (result['candidate_start_token'], result['candidate_start_token'] + len(result['text']))\n",
    "    if long_answer_candidate is not None:\n",
    "        predictions = (long_answer_candidate, '')\n",
    "    else:\n",
    "        predictions = ('', '')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79, 118), '')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([-1258974036110822789, -745542277813407309, -3489053283041023861, -4660970382607895773, -2286041252427312305, -3594846094801386035, 1100531970231406189, -4242445176318660699, -8610711774716247943, -7912859676267745845, 1347288971259022029, -1239741599579606102, -8566118151109196101, 7920718418002827464, 4055855179318578860, 232664088259764773, -5062984347125434513, -26744207835626469, -3769428450906292372, 2909502194213037723, -4322775683193696877, -1173805886994566979, -498275601085723935, -6256881697851641200, -2065095633122306018, -6092597371668069047, -8012102716327631486, -6336020651579045965, 1204288827337360876, -2232903166119770615, -5108190336222695693, -3183208779498643433, -8352843030477839032, 9188546442463987107, 470556784057779418, -6330465807440314122, -5368534122572265804, 1207247341423228973, -3149569811220675888, 5956049813952195977, -8617851792192749121, -88910826615454643, -8079942120175613865, -7157058681297025181, -3630115094940729861, -2331898102646661679, -924532166209509854, -659381440973847628, -6467472195734766021, -4748874516746699670, 979380602111616712, 6357236104337701694, 718328644908116596, -8601880840741158533, -2230117673230036897, -1960481539037275955, -2978800163239341956, 4915614465302333350, 4311493660304100342, 190406553327512575, 6213306834749827575, -3050087507574523308, 3361755184060826790, -6822872928364142515, -2342217877463848447, -1718817990360851693, 8766034038731491838, 8344425567476614063, -2335900678271962549, 6153057216318004474, -4173762245650168251, 726328284631078993, -1458914403349801954, 5481448546087645824, 6807604168630759478, -7975245447510201877, -4145986654551169542, -1851374635399017403, 3026246654784946580, -5977600444622102329, 6677203486440593529, -116673467251978251, 3143098267219565878, -7912917446275843965, 8078004614753233236, 1699258673018415424, -1790672014856006197, 8942226230518515341, -6855163492036335900, -2290200433206917808, -4245244340292987587, 5441768234501370038, 4319712724541914310, 529772882906058814, 7067137684942309386, -4860485422826284019, 107437344188516748, -4508421333366241416, 6487750151702115684, 8450959737287541026, -4617467105261167760, -7893720973221749452, 3086249202080695686, 7755787408066760818, 8155484069063481455, -4897020598228240921, 4279738737380736656, -59591452250878333, -5174354218669872287, 7770117184227306343, -2135428989104836174, 512942171744482497, 6833899876961014698, 7312212568817071125, 5418729114938856534, 4860431881544546745, -23901073947973600, -4159043308971817559, 3126997404306158462, -5337738362122628940, 1830952957837313980, -2066721157005376071, 8188685362873477090, 6286084877144579335, 7996492172224681904, -2382015829568615705, -1363487503998292562, -5829418016047917429, -7019824872367131740, -1567167724192142377, 1319440920141041764, 6310714729623780383, 5697078122347551736, -498216869850038846, 8828691553648112177, -4777352876260495340, 2477807257046472472, -3013417941434408220, -1282307916188794339, -4125374224274459807, 2728228414906581783, -521386453811823583, 2167498496559544446, 1061123991680590844, 2165432788661190020, 2538446403077572144, 2248522536111672263, -8759335434692901364, -691098024792500533, 8163047620788351810, 4635425600222748685, -6644780095764945803, 4402487527582928244, -5571851459920818254, 8747456200740322758, -5122137412557650065, 1943964004035602678, 6527613691925251535, 2105742558472154903, 4058047364107136758, 6522755687197646934])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docwise_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission: Dict[str, str] = OrderedDict()\n",
    "for doc_id in docwise_results:\n",
    "    long_answer, short_answer = predictions[doc_id]\n",
    "    submission(f'{doc_id}_long') = long_answer or '{}:{}'.format(*long_answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst['meta'].metadata['candidate_start_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(params['validation_data_path']) as reader:\n",
    "    for line in reader:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document_text', 'long_answer_candidates', 'question_text', 'annotations', 'document_url', 'example_id'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_token': 16, 'top_level': True, 'end_token': 67},\n",
       " {'start_token': 17, 'top_level': False, 'end_token': 66},\n",
       " {'start_token': 79, 'top_level': True, 'end_token': 118},\n",
       " {'start_token': 118, 'top_level': True, 'end_token': 381},\n",
       " {'start_token': 381, 'top_level': True, 'end_token': 497},\n",
       " {'start_token': 497, 'top_level': True, 'end_token': 607},\n",
       " {'start_token': 607, 'top_level': True, 'end_token': 678},\n",
       " {'start_token': 907, 'top_level': True, 'end_token': 963},\n",
       " {'start_token': 971, 'top_level': True, 'end_token': 1084},\n",
       " {'start_token': 1084, 'top_level': True, 'end_token': 1174},\n",
       " {'start_token': 1174, 'top_level': True, 'end_token': 1316},\n",
       " {'start_token': 1339, 'top_level': True, 'end_token': 1637},\n",
       " {'start_token': 1637, 'top_level': True, 'end_token': 1823},\n",
       " {'start_token': 1830, 'top_level': True, 'end_token': 1903},\n",
       " {'start_token': 1903, 'top_level': True, 'end_token': 2030},\n",
       " {'start_token': 2030, 'top_level': True, 'end_token': 2181},\n",
       " {'start_token': 2181, 'top_level': True, 'end_token': 2370},\n",
       " {'start_token': 2370, 'top_level': True, 'end_token': 2459},\n",
       " {'start_token': 2459, 'top_level': True, 'end_token': 2598},\n",
       " {'start_token': 2460, 'top_level': False, 'end_token': 2597},\n",
       " {'start_token': 2598, 'top_level': True, 'end_token': 2686},\n",
       " {'start_token': 2686, 'top_level': True, 'end_token': 2785},\n",
       " {'start_token': 2687, 'top_level': False, 'end_token': 2784},\n",
       " {'start_token': 2785, 'top_level': True, 'end_token': 2975},\n",
       " {'start_token': 2975, 'top_level': True, 'end_token': 3074},\n",
       " {'start_token': 3074, 'top_level': True, 'end_token': 3186},\n",
       " {'start_token': 3075, 'top_level': False, 'end_token': 3185},\n",
       " {'start_token': 3195, 'top_level': True, 'end_token': 3353},\n",
       " {'start_token': 3361, 'top_level': True, 'end_token': 3391},\n",
       " {'start_token': 3391, 'top_level': True, 'end_token': 3470},\n",
       " {'start_token': 3470, 'top_level': True, 'end_token': 3535},\n",
       " {'start_token': 3535, 'top_level': True, 'end_token': 3682},\n",
       " {'start_token': 3682, 'top_level': True, 'end_token': 3860},\n",
       " {'start_token': 3860, 'top_level': True, 'end_token': 4043},\n",
       " {'start_token': 4043, 'top_level': True, 'end_token': 4063},\n",
       " {'start_token': 4078, 'top_level': True, 'end_token': 4165},\n",
       " {'start_token': 4165, 'top_level': True, 'end_token': 4271},\n",
       " {'start_token': 4271, 'top_level': True, 'end_token': 4290},\n",
       " {'start_token': 4290, 'top_level': True, 'end_token': 4321},\n",
       " {'start_token': 4291, 'top_level': False, 'end_token': 4302},\n",
       " {'start_token': 4302, 'top_level': False, 'end_token': 4320},\n",
       " {'start_token': 4321, 'top_level': True, 'end_token': 4336},\n",
       " {'start_token': 4336, 'top_level': True, 'end_token': 4376},\n",
       " {'start_token': 4376, 'top_level': True, 'end_token': 4523},\n",
       " {'start_token': 4523, 'top_level': True, 'end_token': 4652},\n",
       " {'start_token': 4652, 'top_level': True, 'end_token': 4827},\n",
       " {'start_token': 4827, 'top_level': True, 'end_token': 4940},\n",
       " {'start_token': 4940, 'top_level': True, 'end_token': 5047},\n",
       " {'start_token': 5047, 'top_level': True, 'end_token': 5183},\n",
       " {'start_token': 5183, 'top_level': True, 'end_token': 5254},\n",
       " {'start_token': 5254, 'top_level': True, 'end_token': 5335},\n",
       " {'start_token': 5335, 'top_level': True, 'end_token': 5374},\n",
       " {'start_token': 5403, 'top_level': True, 'end_token': 5487},\n",
       " {'start_token': 5493, 'top_level': True, 'end_token': 5548},\n",
       " {'start_token': 5548, 'top_level': True, 'end_token': 5626},\n",
       " {'start_token': 5626, 'top_level': True, 'end_token': 5744},\n",
       " {'start_token': 5744, 'top_level': True, 'end_token': 5793},\n",
       " {'start_token': 5793, 'top_level': True, 'end_token': 5822},\n",
       " {'start_token': 5822, 'top_level': True, 'end_token': 5857},\n",
       " {'start_token': 5857, 'top_level': True, 'end_token': 5923},\n",
       " {'start_token': 5923, 'top_level': True, 'end_token': 6017},\n",
       " {'start_token': 6017, 'top_level': True, 'end_token': 6059},\n",
       " {'start_token': 6059, 'top_level': True, 'end_token': 6120},\n",
       " {'start_token': 6120, 'top_level': True, 'end_token': 6185},\n",
       " {'start_token': 6197, 'top_level': True, 'end_token': 6226},\n",
       " {'start_token': 6226, 'top_level': True, 'end_token': 6260},\n",
       " {'start_token': 6276, 'top_level': True, 'end_token': 6331},\n",
       " {'start_token': 6331, 'top_level': True, 'end_token': 6382},\n",
       " {'start_token': 6382, 'top_level': True, 'end_token': 6419},\n",
       " {'start_token': 6419, 'top_level': True, 'end_token': 6503},\n",
       " {'start_token': 6503, 'top_level': True, 'end_token': 6533},\n",
       " {'start_token': 6533, 'top_level': True, 'end_token': 6554},\n",
       " {'start_token': 6554, 'top_level': True, 'end_token': 6616},\n",
       " {'start_token': 6616, 'top_level': True, 'end_token': 6651},\n",
       " {'start_token': 6667, 'top_level': True, 'end_token': 6728},\n",
       " {'start_token': 6728, 'top_level': True, 'end_token': 6815},\n",
       " {'start_token': 6815, 'top_level': True, 'end_token': 6868},\n",
       " {'start_token': 6868, 'top_level': True, 'end_token': 6906},\n",
       " {'start_token': 6906, 'top_level': True, 'end_token': 6960},\n",
       " {'start_token': 6960, 'top_level': True, 'end_token': 7045},\n",
       " {'start_token': 7045, 'top_level': True, 'end_token': 7250},\n",
       " {'start_token': 7250, 'top_level': True, 'end_token': 7354},\n",
       " {'start_token': 7376, 'top_level': True, 'end_token': 7501},\n",
       " {'start_token': 7501, 'top_level': True, 'end_token': 7537},\n",
       " {'start_token': 7546, 'top_level': True, 'end_token': 7771},\n",
       " {'start_token': 7783, 'top_level': True, 'end_token': 7908},\n",
       " {'start_token': 7908, 'top_level': True, 'end_token': 7959},\n",
       " {'start_token': 7959, 'top_level': True, 'end_token': 8141},\n",
       " {'start_token': 8141, 'top_level': True, 'end_token': 8291},\n",
       " {'start_token': 8291, 'top_level': True, 'end_token': 8485},\n",
       " {'start_token': 8485, 'top_level': True, 'end_token': 8597},\n",
       " {'start_token': 8611, 'top_level': True, 'end_token': 8652},\n",
       " {'start_token': 8652, 'top_level': True, 'end_token': 8740},\n",
       " {'start_token': 8740, 'top_level': True, 'end_token': 8757},\n",
       " {'start_token': 8757, 'top_level': True, 'end_token': 8819},\n",
       " {'start_token': 8758, 'top_level': False, 'end_token': 8801},\n",
       " {'start_token': 8801, 'top_level': False, 'end_token': 8818},\n",
       " {'start_token': 8819, 'top_level': True, 'end_token': 8926},\n",
       " {'start_token': 8936, 'top_level': True, 'end_token': 8998},\n",
       " {'start_token': 8998, 'top_level': True, 'end_token': 9125},\n",
       " {'start_token': 9125, 'top_level': True, 'end_token': 9206},\n",
       " {'start_token': 9220, 'top_level': True, 'end_token': 9279},\n",
       " {'start_token': 9287, 'top_level': True, 'end_token': 9327},\n",
       " {'start_token': 9327, 'top_level': True, 'end_token': 9490},\n",
       " {'start_token': 9496, 'top_level': True, 'end_token': 9554},\n",
       " {'start_token': 9554, 'top_level': True, 'end_token': 9718},\n",
       " {'start_token': 9718, 'top_level': True, 'end_token': 9783},\n",
       " {'start_token': 9783, 'top_level': True, 'end_token': 9824},\n",
       " {'start_token': 9838, 'top_level': True, 'end_token': 9874},\n",
       " {'start_token': 9839, 'top_level': False, 'end_token': 9849},\n",
       " {'start_token': 9842, 'top_level': False, 'end_token': 9848},\n",
       " {'start_token': 9865, 'top_level': False, 'end_token': 9873},\n",
       " {'start_token': 9881, 'top_level': True, 'end_token': 9915},\n",
       " {'start_token': 9882, 'top_level': False, 'end_token': 9891},\n",
       " {'start_token': 9891, 'top_level': False, 'end_token': 9899},\n",
       " {'start_token': 9899, 'top_level': False, 'end_token': 9907},\n",
       " {'start_token': 9907, 'top_level': False, 'end_token': 9914},\n",
       " {'start_token': 9922, 'top_level': True, 'end_token': 9986},\n",
       " {'start_token': 9923, 'top_level': False, 'end_token': 9932},\n",
       " {'start_token': 9932, 'top_level': False, 'end_token': 9942},\n",
       " {'start_token': 9942, 'top_level': False, 'end_token': 9948},\n",
       " {'start_token': 9948, 'top_level': False, 'end_token': 9955},\n",
       " {'start_token': 9959, 'top_level': False, 'end_token': 9966},\n",
       " {'start_token': 9966, 'top_level': False, 'end_token': 9985},\n",
       " {'start_token': 9993, 'top_level': True, 'end_token': 10063},\n",
       " {'start_token': 9994, 'top_level': False, 'end_token': 10007},\n",
       " {'start_token': 10007, 'top_level': False, 'end_token': 10020},\n",
       " {'start_token': 10020, 'top_level': False, 'end_token': 10035},\n",
       " {'start_token': 10035, 'top_level': False, 'end_token': 10045},\n",
       " {'start_token': 10045, 'top_level': False, 'end_token': 10054},\n",
       " {'start_token': 10054, 'top_level': False, 'end_token': 10062},\n",
       " {'start_token': 10070, 'top_level': True, 'end_token': 10123},\n",
       " {'start_token': 10089, 'top_level': False, 'end_token': 10094},\n",
       " {'start_token': 10098, 'top_level': False, 'end_token': 10105},\n",
       " {'start_token': 10105, 'top_level': False, 'end_token': 10110},\n",
       " {'start_token': 10114, 'top_level': False, 'end_token': 10119},\n",
       " {'start_token': 10133, 'top_level': True, 'end_token': 11107},\n",
       " {'start_token': 10134, 'top_level': False, 'end_token': 10192},\n",
       " {'start_token': 10192, 'top_level': False, 'end_token': 10265},\n",
       " {'start_token': 10265, 'top_level': False, 'end_token': 10309},\n",
       " {'start_token': 10309, 'top_level': False, 'end_token': 10370},\n",
       " {'start_token': 10370, 'top_level': False, 'end_token': 10447},\n",
       " {'start_token': 10447, 'top_level': False, 'end_token': 10657},\n",
       " {'start_token': 10657, 'top_level': False, 'end_token': 10685},\n",
       " {'start_token': 10685, 'top_level': False, 'end_token': 10710},\n",
       " {'start_token': 10710, 'top_level': False, 'end_token': 10769},\n",
       " {'start_token': 10769, 'top_level': False, 'end_token': 10805},\n",
       " {'start_token': 10805, 'top_level': False, 'end_token': 10846},\n",
       " {'start_token': 10846, 'top_level': False, 'end_token': 10872},\n",
       " {'start_token': 10872, 'top_level': False, 'end_token': 10915},\n",
       " {'start_token': 10915, 'top_level': False, 'end_token': 10944},\n",
       " {'start_token': 10944, 'top_level': False, 'end_token': 11041},\n",
       " {'start_token': 11041, 'top_level': False, 'end_token': 11106}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line['long_answer_candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.74120527e-12, 3.58257781e-12, 2.27677772e-12, 4.98013714e-11,\n",
       "       1.75781449e-12, 3.93584228e-11, 2.65977018e-10, 2.47831053e-12,\n",
       "       1.48078882e-10, 1.00000000e+00, 5.00546566e-12, 2.54231983e-11,\n",
       "       2.72890814e-13, 7.21567988e-13, 1.86188386e-13, 8.06734440e-14,\n",
       "       1.38707229e-13, 2.50405301e-13, 1.61096356e-13, 2.14020072e-13,\n",
       "       1.43250090e-13, 5.75047226e-13, 1.77148538e-13, 1.84621090e-13,\n",
       "       2.11917967e-13, 2.64569508e-13, 9.17822784e-13, 1.50097315e-13,\n",
       "       1.70493082e-13, 8.20020321e-14, 1.00831520e-13, 1.08939645e-13,\n",
       "       2.11119189e-09, 1.27482186e-13, 1.80516761e-13, 1.32638651e-13,\n",
       "       7.32685017e-13, 6.41841940e-13, 1.78506610e-13, 1.64872605e-13,\n",
       "       1.49719890e-13, 1.15443056e-13, 3.35153482e-13, 7.36383719e-13,\n",
       "       1.59665656e-13, 5.13281431e-12, 6.47599108e-14, 1.55645164e-13,\n",
       "       2.10130497e-13, 1.35983144e-13, 2.09678087e-13, 2.71303759e-13,\n",
       "       1.35278968e-13, 1.80635942e-13, 9.07738579e-14, 2.36311052e-13,\n",
       "       8.60806042e-14, 1.53300224e-13, 3.96085379e-14, 1.39254039e-10,\n",
       "       2.54370933e-13, 7.60577853e-14, 2.28954594e-12, 2.86530917e-13,\n",
       "       9.91177192e-13, 1.12340320e-13, 1.89602227e-13, 1.34226799e-12,\n",
       "       2.30073827e-13, 2.01402900e-13, 2.36674151e-13, 1.61017488e-12,\n",
       "       3.74780339e-13, 2.78607676e-13, 4.73873158e-14, 7.40312420e-14,\n",
       "       5.00771435e-14, 6.31442598e-14, 1.43780306e-13, 1.80950768e-13,\n",
       "       2.86127323e-13, 6.66950287e-14, 1.35060339e-13, 7.63085884e-14,\n",
       "       3.48503805e-13, 3.25895642e-13, 1.79118127e-13, 2.80867289e-13,\n",
       "       1.04444007e-13, 1.14332507e-13, 3.86560629e-13, 2.94698592e-13,\n",
       "       1.41404941e-13, 1.10644431e-13, 1.45368711e-12, 5.78536581e-14,\n",
       "       1.81957558e-13, 1.25704853e-13, 8.64002067e-14, 1.62752055e-13,\n",
       "       7.70586123e-14, 1.47830316e-13, 1.39321036e-13, 6.16583539e-14,\n",
       "       8.70268823e-14, 1.55629727e-13, 1.43268942e-13, 3.17629834e-14,\n",
       "       7.33972605e-11, 5.55464745e-13, 1.50941081e-13, 3.45903861e-13,\n",
       "       4.08233343e-13, 3.42351439e-14, 6.38953192e-13, 1.44448255e-13,\n",
       "       1.50049230e-13, 1.01192573e-13, 2.62430512e-13, 1.06832152e-13,\n",
       "       1.38463771e-13, 1.46427209e-13, 1.53308112e-13, 2.01282703e-13,\n",
       "       2.41543845e-13, 1.73278736e-13, 1.64283409e-13, 2.06987178e-13,\n",
       "       1.33547843e-11, 1.26703091e-13, 1.52638495e-13, 4.30826029e-13,\n",
       "       7.08397533e-13, 1.25090883e-13, 1.43765222e-13, 8.22449747e-14,\n",
       "       3.45213116e-13, 3.46250230e-14, 3.69331640e-14, 8.63348089e-14,\n",
       "       4.95773670e-13, 1.06347677e-13, 6.80617672e-13, 1.15027860e-13,\n",
       "       1.50119649e-13, 2.82272740e-13, 5.56790365e-14, 7.26551794e-14,\n",
       "       3.53831954e-13, 5.72597457e-14, 6.74246358e-13, 2.11620286e-13,\n",
       "       6.97380250e-13, 1.29500618e-13, 2.24693175e-13, 1.20166179e-13,\n",
       "       3.68325840e-13, 7.92834765e-14, 2.06441784e-14, 5.15950943e-13,\n",
       "       2.48993182e-13, 9.80708353e-13, 1.61234063e-13, 1.08653897e-13,\n",
       "       5.34519260e-14, 1.81787582e-13, 7.08567455e-14, 9.14258022e-14,\n",
       "       3.37515497e-13, 1.78094085e-13, 1.91009860e-13, 3.66211700e-13,\n",
       "       2.02822297e-13, 8.38485572e-14, 5.07057199e-14, 9.28949571e-14,\n",
       "       4.90234006e-14, 3.78465976e-14, 1.94138783e-14, 6.87600747e-14,\n",
       "       1.17328131e-13, 4.19739452e-14, 5.53138535e-14, 4.16571549e-14,\n",
       "       3.27892715e-13, 8.86293195e-14, 6.63070376e-10, 6.87472201e-14,\n",
       "       6.32127068e-14, 2.70624641e-13, 2.34721164e-14, 8.31628874e-14,\n",
       "       5.48687445e-14, 5.56428655e-13, 1.01755986e-13, 1.09258644e-13,\n",
       "       6.09540765e-14, 1.08592775e-13, 1.76084042e-13, 3.16147960e-13,\n",
       "       4.41915757e-14, 5.72240484e-14, 8.48471345e-14, 5.51224105e-13,\n",
       "       4.81368621e-14, 8.56227659e-14, 1.70638189e-13, 5.44868377e-14,\n",
       "       3.27685768e-13, 1.43538366e-13, 6.17865893e-13, 9.56647752e-14,\n",
       "       1.92664813e-13, 2.21974200e-13, 4.08869783e-14, 3.72950759e-12,\n",
       "       5.79364776e-14, 8.70997813e-14, 8.99683838e-14, 2.52733896e-13,\n",
       "       6.01070165e-14, 7.29339752e-14, 3.99785700e-13, 5.67260377e-13,\n",
       "       3.72363951e-14, 4.91042550e-14, 3.88516476e-13, 7.63398879e-14,\n",
       "       1.52752377e-13, 9.03639346e-14, 1.47020213e-13, 1.34459392e-13,\n",
       "       7.05710785e-14, 1.98488551e-13, 7.58182173e-14, 8.65233991e-14,\n",
       "       1.76245317e-13, 1.33387577e-13, 1.60650207e-13, 6.15307704e-14,\n",
       "       1.08232976e-13, 1.06543396e-13, 9.40340809e-14, 1.43257192e-13,\n",
       "       4.29716247e-14, 3.26882531e-12, 9.60958133e-14, 7.95044933e-12,\n",
       "       8.16575675e-14, 3.57347398e-12, 5.74691661e-14, 1.99925932e-13,\n",
       "       5.86731347e-13, 1.63968253e-12, 2.81769643e-14, 2.53343592e-12,\n",
       "       4.91131766e-13, 2.41378505e-13, 9.32367031e-13, 3.43570279e-13,\n",
       "       2.64568640e-12, 1.24575697e-12, 1.67808543e-13, 2.21759649e-13,\n",
       "       1.71135567e-13, 7.22268518e-14, 2.84355357e-13, 2.17144648e-13,\n",
       "       4.84841557e-14, 1.14963825e-13, 6.15975283e-12, 2.19278822e-14,\n",
       "       5.17631321e-14], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['start_logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fedc3ab9ef0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(res['start_logits'].reshape(1, -1), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['start_logits'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['end_logits'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_id': -1258974036110822789,\n",
       " 'text': ['<P>',\n",
       "  'Several',\n",
       "  'diverse',\n",
       "  'political',\n",
       "  'groups',\n",
       "  'coalesced',\n",
       "  'in',\n",
       "  'the',\n",
       "  'late',\n",
       "  '1960s',\n",
       "  'in',\n",
       "  'the',\n",
       "  'formation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Parti',\n",
       "  'Québécois',\n",
       "  ',',\n",
       "  'a',\n",
       "  'provincial',\n",
       "  'political',\n",
       "  'party',\n",
       "  '.',\n",
       "  'Since',\n",
       "  '1968',\n",
       "  'the',\n",
       "  'party',\n",
       "  'has',\n",
       "  'appealed',\n",
       "  'for',\n",
       "  'constitutional',\n",
       "  'negotiations',\n",
       "  'on',\n",
       "  'the',\n",
       "  'matter',\n",
       "  'of',\n",
       "  'provincial',\n",
       "  'sovereignty',\n",
       "  ',',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'holding',\n",
       "  'two',\n",
       "  'provincial',\n",
       "  'referendums',\n",
       "  'on',\n",
       "  'the',\n",
       "  'matter',\n",
       "  '.',\n",
       "  'The',\n",
       "  'first',\n",
       "  ',',\n",
       "  'which',\n",
       "  'occurred',\n",
       "  'in',\n",
       "  '1980',\n",
       "  ',',\n",
       "  'asked',\n",
       "  'whether',\n",
       "  'Quebecers',\n",
       "  'wished',\n",
       "  'to',\n",
       "  'open',\n",
       "  'constitutional',\n",
       "  'negotiations',\n",
       "  'with',\n",
       "  'the',\n",
       "  'federal',\n",
       "  'government',\n",
       "  '(',\n",
       "  'and',\n",
       "  'other',\n",
       "  'provinces',\n",
       "  ')',\n",
       "  'for',\n",
       "  'the',\n",
       "  'intended',\n",
       "  'purpose',\n",
       "  'of',\n",
       "  'establishing',\n",
       "  'a',\n",
       "  '``',\n",
       "  'sovereignty',\n",
       "  '-',\n",
       "  'association',\n",
       "  \"''\",\n",
       "  'pact',\n",
       "  'between',\n",
       "  'the',\n",
       "  'province',\n",
       "  'of',\n",
       "  'Quebec',\n",
       "  'and',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'Canada',\n",
       "  '.',\n",
       "  'Approximately',\n",
       "  '60',\n",
       "  '%',\n",
       "  'of',\n",
       "  'Quebec',\n",
       "  \"'s\",\n",
       "  'voting',\n",
       "  'public',\n",
       "  'rejected',\n",
       "  'the',\n",
       "  'idea',\n",
       "  'put',\n",
       "  'forth',\n",
       "  'by',\n",
       "  'Parti',\n",
       "  'Québécois',\n",
       "  'leader',\n",
       "  'René',\n",
       "  'Lévesque',\n",
       "  '.',\n",
       "  'The',\n",
       "  'matter',\n",
       "  'was',\n",
       "  'dropped',\n",
       "  'by',\n",
       "  'the',\n",
       "  'party',\n",
       "  'for',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  '1980s',\n",
       "  ',',\n",
       "  'especially',\n",
       "  'after',\n",
       "  'the',\n",
       "  'patriation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Canadian',\n",
       "  'constitution',\n",
       "  'without',\n",
       "  'the',\n",
       "  'consent',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Parti',\n",
       "  'Québécois',\n",
       "  'government',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'creation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'federal',\n",
       "  'Charter',\n",
       "  'of',\n",
       "  'Rights',\n",
       "  'and',\n",
       "  'Freedoms',\n",
       "  ',',\n",
       "  'which',\n",
       "  'enshrined',\n",
       "  'the',\n",
       "  'protection',\n",
       "  'of',\n",
       "  'the',\n",
       "  'French',\n",
       "  'language',\n",
       "  'and',\n",
       "  'French',\n",
       "  '-',\n",
       "  'Canadian',\n",
       "  'culture',\n",
       "  'in',\n",
       "  'Canada',\n",
       "  '.',\n",
       "  'In',\n",
       "  '1995',\n",
       "  ',',\n",
       "  'after',\n",
       "  'two',\n",
       "  'failed',\n",
       "  'attempts',\n",
       "  'by',\n",
       "  'the',\n",
       "  'Mulroney',\n",
       "  'government',\n",
       "  'to',\n",
       "  'secure',\n",
       "  'Quebec',\n",
       "  \"'s\",\n",
       "  'ratification',\n",
       "  'of',\n",
       "  'amendments',\n",
       "  'to',\n",
       "  'the',\n",
       "  'constitution',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Parti',\n",
       "  'Québécois',\n",
       "  'held',\n",
       "  'a',\n",
       "  'second',\n",
       "  'referendum',\n",
       "  ',',\n",
       "  'though',\n",
       "  'on',\n",
       "  'this',\n",
       "  'occasion',\n",
       "  'the',\n",
       "  'question',\n",
       "  'was',\n",
       "  ',',\n",
       "  'albeit',\n",
       "  'obliquely',\n",
       "  'asked',\n",
       "  ',',\n",
       "  'whether',\n",
       "  'one',\n",
       "  'wished',\n",
       "  'for',\n",
       "  'the',\n",
       "  'independence',\n",
       "  'of',\n",
       "  'the',\n",
       "  'province',\n",
       "  'of',\n",
       "  'Quebec',\n",
       "  'from',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'Canada',\n",
       "  '.',\n",
       "  'The',\n",
       "  'response',\n",
       "  'was',\n",
       "  'again',\n",
       "  'in',\n",
       "  'the',\n",
       "  'negative',\n",
       "  ',',\n",
       "  'though',\n",
       "  'this',\n",
       "  'time',\n",
       "  'by',\n",
       "  'a',\n",
       "  'far',\n",
       "  'closer',\n",
       "  'margin',\n",
       "  ',',\n",
       "  'with',\n",
       "  'a',\n",
       "  'mere',\n",
       "  '50.58',\n",
       "  '%',\n",
       "  'against',\n",
       "  'the',\n",
       "  'proposal',\n",
       "  '.',\n",
       "  '</P>'],\n",
       " 'query': ['the',\n",
       "  'name',\n",
       "  'of',\n",
       "  'the',\n",
       "  'separatist',\n",
       "  'political',\n",
       "  'party',\n",
       "  'in',\n",
       "  'quebec']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst['meta'].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.3169417, -0.6555685, -3.7547233, -4.293389 ], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['label_logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_relevant': 0, 'NONE': 1, 'YES': 2, 'NO': 3}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab.get_token_to_index_vocabulary('answer_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
